---
title: "PARTIE I. Accompagnement au changement"
author: "équipe KALLM"
date: "2024-06-07"
format: html
---

Les cas d'usages des LLMs sont variés et avant de se lancer et innover grâce aux LLMs, il est nécessaire de bien identifier le besoin qui amène l'utilisation d'un LLM. Pour quoi faire ? Pour quels usages ? Est-ce pour de la génération de texte ? Pour de la classification ? ou pour des interactions conversationnelles ?
L'objectif de ce chapitre est d'accompagner la réflexion autour de l'identification du besoin et de la collecte des données, avec les différents types de cas d'usages impliquant des LLMs. 

Au sein des administrations, les cas d'usage de LLM ci-dessous sont en cours d'expérimentation, soit en production.

## A. Cas d’usage
Des LLM peuvent être utilisés pour :

-	**Labelliser / classifier les textes d’un corpus traitant d’un sujet, selon certaines catégories**. 
Par exemple, des LLMS peuvent être utilisés pour labelliser des articles de presse traitant de décisions de politique monétaire, selon les catégories « décision attendue », « décision surprenante », « ne sait pas ». Ils peuvent également classer des documents de recherche clinique selon différentes thématiques et disciplines, tout en permettant une recherche sémantique avancée. 

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Ministère en charge de la santé| SIRANo | dgos-sirano@sante.gouv.fr | Expérimentation  |
|Banque de France |Étude de l’impact des surprises monétaires sur les taux de change|jean-charles.bricongne@banque-france.fr| Recherche|
|Banque de France  |Anticipation d’inflation |jean-charles.bricongne@banque-france.fr <br>olivier.debandt@banque-france.fr <br> Thomas.RENAULT.external@banque-france.fr |Recherche  |


Par exemple, des LLMS peuvent être utilisés pour labellisés des articles de presse traitant de décisions de politique monétaire, selon les catégories « décision attendue », « décision surprenante », « ne sait pas ».

-	**Identifier les thématiques traitées dans un corpus**.
Par exemple, des LLMs peuvent être utilisés pour identifier les thématiques développées dans le champ Commentaire d’une enquête.

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Banque de France | Enquête sur les Tendances régionales | Farid.OUKACI@banque-france.fr <br> Olivier.LANTRAN@banque-france.fr | Expérimentation  |
|LabIA DNUM | [LLamandement](https://gitlab.adullact.net/dgfip/projets-ia/llamandement) : LLM finetuné permettant d'accélerer le traitement d'amendements et projets de loi (notamment via la synthétisation des textes).| Farid.OUKACI@banque-france.fr <br> Olivier.LANTRAN@banque-france.fr | Expérimentation  |
		

-	**Faire une analyse de sentiment d’un corpus traitant d’une thématique**.
Par exemple, des LLMs peuvent être utilisés pour faire une analyse de sentiment (ex : positif, négatif ou neutre) d’une thématique émergeant d’un champ « Commentaire » d’une enquête et traitant d’une perception du climat des affaires.

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Banque de France | Enquête sur les Tendances régionales | Farid.OUKACI@banque-france.fr <br> Olivier.LANTRAN@banque-france.fr | Expérimentation  |
		

-	**Interroger une base de documents textuels (pdf, code, etc…) (retrieval augmented generation)**. 
Les documents sont découpés en paragraphes (chunks). Les réponses aux questions posées sont générées sur la base de paragraphes idoines existant dans la base. Les paragraphes qui ont servi à l’élaboration de la réponse sont indiqués en regard de celle-ci, et peuvent être consultés.

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Banque de France | Chatbdf | Nicolas.THOMAZO@banque-france.fr <br> Guillaume.LOMBARDO@banque-france.fr <br> Alix.DECREMOUX@banque-france.fr  | Passage en production prévu en décembre 2025  |
		
-	**Requêter sur des bases de données codées en SQL : à une interrogation exprimée en langage naturel sur une base en SQL, un code en SQL servant à la requête est renvoyé**.
Par exemple, à l’interrogation « trouve-moi la date de naissance de l’individu I », un code SQL est renvoyé permettant d’effectuer la requête

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Banque de France | Text2SQL | Guillaume.LOMBARDO@banque-france.fr | Passage en production par la BCE en décembre 2024 |


-   **Extraire des données à partir de documents textuels**
Par exemple, à partir de documents réglementaires extraire 15 informations-clés et stocker celles-ci dans une base de données

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
|Banque de France | Veridic | Guillaume.LOMBARDO@banque-france.fr | Passage en production prévu fin 2025 |

-   **Classifier des accords d'entreprise**
Les accords d'entreprise sont publiés sur [LégiFrance](https://www.legifrance.gouv.fr/liste/acco).
Ces accords peuvent concerner plusieurs thématiques (télétravail, compte épargne temps, droit à la deconnexion).Ces thématiques sont déclarés par les entreprises et sont éventuellement corrigées par la Direction Générale du Travail.Le besoin est alors de détecter automatiquement les thématiques à la lecture de l'accord. Un jeu de données est disponible à l'adresse suivante : [accords_publics_xx_to_2022_themes_et_texte.parquet](https://minio.lab.sspcloud.fr/cthiounn2/Accords/accords_publics_xx_to_2022_themes_et_texte.parquet)

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
| |  |  |  |

-   **IA générative**

| Institution	|	Nom du Projet	|	Contact | Expérimentation/Production/Recherche|
| -------- | ------- |------- |------- |
| |  |  |  |

Projet mené par le LabIA de la DINUM
    - [Albert github](https://github.com/etalab-ia/albert) : Outils de déploiements des modèles Albert
    - [Modèles Albert](Ajouter adresse Hugging Face)
    - [Albert France Services](https://www.france-services.gouv.fr/taxonomy/term/174#:~:text=%C2%AB%20Albert%20France%20services%20%C2%BB%20facilite%20les,des%20cas%20d%27usage%20donn%C3%A9s.) : Projet à destination de
    [France Service](https://www.france-services.gouv.fr/) et visant à appuyer ses conseillers dans la réalisation de leurs missions. Ce projet se base principalement
    [Albert github](https://github.com/etalab-ia/albert)
    [Albert hugging face]()


> Pour plus de projets IA (au sens large) dans l'administration se référer au lien : https://grist.numerique.gouv.fr/o/beta-gouv-ia/9wTgwEbwqmwW/Ressources/p/1

## (Intégrer les cas d'usage ci-dessous au sein des catégories pré-citées ou en ajouter en faisant ressortir leur spécificité)

## Description cas d'usage

 1. Utilisation des SLM pour la recherche thématique simple en français (en cours, Zhanna)<br>
Malgré la disponibilité et l’attractivité des « grands » modèles langages comme GPT et Mixtral, l’utilisation des petits modèles classiques est parfois plus avantageuse, surtout quand les ressources techniques ou l’accès aux données sont restreints.\
C’est vrai dans le cas d’utilisation d’un SLM basé sur un modèle devenu classique, BERT qui donne la naissance à milliers de modèles spécialisés comme [CamemBERT](https://arxiv.org/abs/1911.03894) un modèle en français ou encore [sBERT ou sentenceTransformers](https://sbert.net/) permettant un entraînement spécialisé pour une recherche sémantique.
<br>
**ici plus d'information sur les avantages des SLM (données, environement, spécialisation, travail en local, technique)
<br>
Nous considérons un exemple d’utilisation de CamemBERT-base et un exemple de sBERT :

1. [camembert-bio-base](https://huggingface.co/almanach/camembert-bio-base) avec ses 111M de paramètres, pour une recherche thématique dans des textes scientifiques biomédicaux.
Nous utiliserons les transformers de [HuggingFace](https://github.com/huggingface/transformers)
```python
from transformers import AutoTokenizer, AutoModelForMaskedLM
biotokenizer = AutoTokenizer.from_pretrained("almanach/camembert-bio-base")
biomodel = AutoModelForMaskedLM.from_pretrained("almanach/camembert-bio-base")
```

2. [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
```python
import requests

api_url = f"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}"
headers = {"Authorization": f"Bearer {hf_token}"}
```
