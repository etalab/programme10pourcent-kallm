
# PARTIE III. Deploiements

## 4. Infras dispos pour l’administration (Thibault Katia)

Dans beaucoup de cas l'infrastructure est un des principaux freins à la mise en production d'un cas d'usage d'IA générative. L'acquisition d'un cluster GPUs n'est pas toujours une possibilité pour des questions budgétaires ou techniques. Cependant, plusieurs solutions sont disponibles (ou en cours de construction) à destination des administrations pour externaliser cette infrastructure. 

Cette approche est d'ailleurs en phase avec la directive ["cloud au centre"](https://www.legifrance.gouv.fr/download/pdf/circ?id=45446) qui encourage l'utilisation d'infrastructure externalisée pour les projets informatiques de l'administration.

Dans ce cadre, la principale variable a prendre en compte est les contraintes de sécurité de l'application. Cette question va à la fois déterminer les solutions accessibles et imposer des choix architecturaux. Un guide a été publié par l'Anssi sur le sujet en avril 2024 : [RECOMMANDATIONS DE SÉCURITÉ
POUR UN SYSTÈME D'IA GÉNÉRATIVE](https://cyber.gouv.fr/sites/default/files/document/Recommandations_de_s%C3%A9curit%C3%A9_pour_un_syst%C3%A8me_d_IA_g%C3%A9n%C3%A9rative.pdf)

3 principales solutions sont possibles : 
- [Cloud Public](#cloud-public)
- [Cloud externe](#cloud-externe)
- [API inférence](#api-inference)


### A. Cloud Public

Bien que l'état dispose de plusieurs offres cloud internes, la mise à disposition de GPU est encore très peu mature et peu développée

1. [SSP Cloud](https://datalab.sspcloud.fr/?lang=fr)

A ce jour, le SSP Cloud via sa plateforme ONYXIA, est la principale plateforme publique mettant à disposition des GPUs à ces utilisateurs. Les ressources sont cependant très limitées et la plateforme est plus orientée autour du développement de projet que de la mise en production.

cf [Déploiement d'un LLM sur SSP Cloud](#Déploiement d'un LLM sur SSP Cloud)

2. Cloud PI

Cloud PI est le cloud du ministère de l'intérieur 

> TODO Obtenir des infos sur la disponibilté éventuelle de GPU dans PI ? 

3. Nubo

Via Nubonyxia 

> TODO Roadmap du Bercyhub sur ce sujet ? 

### B. Cloud externe

La qualificiation [SecNumCloud](https://cyber.gouv.fr/secnumcloud-pour-les-fournisseurs-de-services-cloud) a été mis en place par l'ANSSI pour assurer des normes de sécurité aux utilisateurs de produits cloud. A ce jour, peu d'entreprises ont acquis cette qualification

1. [Dassault - Outscale](https://fr.outscale.com/) **IAAS** 
2. [Thales - Sens](https://www.s3ns.io/) (Implémentation de GCP sur une infrastructure sécurisée) **PAAS** 
3. [Cloud Temple](https://www.cloud-temple.com/) **IAAS ?** 
4. ... 

### C. API inférence 

1. Public :  Albert API

2. Externe non sécurisée :

- [Mistral API](https://mistral.ai/fr/)
- [Hugging face - inference endpoint](https://huggingface.co/inference-endpoints/dedicated)
- [Groq](https://wow.groq.com/why-groq/)

### 5. Déploiement d'un LLM sur SSP Cloud

Sur le DataLab SSP Cloud, il est possible de déployer des LLM à des fins d'expérimentation. Plusieurs cas sont possibles :

A. Utiliser des librairies d'API de LLM (vLLM, etc.)
B. Déployer des containers Docker avec Kube et Helm

#### A. Déploiement par API

* Vous pouvez lancer un service VSCode avec une GPU et installer une API de LLM

#### B. Déploiement par image Docker

* Créer une image Docker et la mettre à disposition (Dockerhub) : exemple applicatif avec Streamlit
* Déployer avec Kube et Helm en utilisant un service VSCode avec les droits d'admin pour Kube


Exemple avec Kube :

```bash
kubectl create deployment mon-deploiement --image=mon-image-docker
```


```bash
kubectl proxy
```

